{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Author: Joyce Maria do Carmo de Sá, 18 de Agosto de 2022**\n",
    "\n",
    "Todos os experimentos realizados assim como as métricas de avaliação podem ser observados no dagshub:   \n",
    "https://dagshub.com/joycesafg/DataMaster_Case/experiments\n",
    "\n",
    "O objetivo é desenvolver um modelo, onde consigamos identificar clientes insatisfeitos, para que possamos atuar com alguma campanha e evitar o churnning desses clientes de forma a obter o maior lucro. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comandos iniciais para recuperar os dados - É necessario ter uma chave kaggle (kaggle.json) para fazer o download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ! pip install kaggle\n",
    "# ! mkdir ~/.kaggle\n",
    "# ! cp kaggle.json ~/.kaggle/\n",
    "# ! chmod 600 ~/.kaggle/kaggle.json\n",
    "# ! kaggle competitions download -c santander-customer-satisfaction -f train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapa que transforma os dados de zip para o dataframe pandas - O dado tambem esta disponivel como csv na pasta \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# zip_file_path = 'train.csv.zip'\n",
    "# extract_to = 'train_dataset'\n",
    "\n",
    "# os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(extract_to)\n",
    "\n",
    "# extracted_files = zip_ref.namelist()\n",
    "\n",
    "# csv_file_path = os.path.join(extract_to, extracted_files[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports necessários para executar o código\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import mlflow\n",
    "import dagshub\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como instalar os requisitos\n",
    "\n",
    "Para instalar os requisitos necessários para executar este notebook, você pode seguir os passos abaixo:\n",
    "\n",
    "1. Certifique-se de ter o Python instalado em sua máquina. Recomendamos usar o Python 3.6 ou superior.\n",
    "2. Crie um ambiente virtual (opcional, mas recomendado):\n",
    "    ```bash\n",
    "    python -m venv myenv\n",
    "    source myenv/bin/activate  # No Windows, use `myenv\\Scripts\\activate`\n",
    "    ```\n",
    "3. Instale os pacotes listados no arquivo `requirements_dev.txt`:\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicialização do mlflow e do dagsHub para o acompanhamento do experimento\n",
    "\n",
    "dagshub.init(repo_owner='joycesafg', repo_name='DataMaster_Case', mlflow=True)\n",
    "mlflow.set_tracking_uri(uri=\"https://dagshub.com/joycesafg/DataMaster_Case.mlflow\")\n",
    "mlflow.set_experiment(\"Data_Master_ML_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset\n",
    "df_case = pd.read_csv('data/train.csv')\n",
    "\n",
    "#Check the types of the columns\n",
    "print(df_case.dtypes.value_counts())\n",
    "\n",
    "#Check if there are any missing values\n",
    "print(df_case.isnull().values.any())\n",
    "\n",
    "# 3.96% of the clients are unsatisfied\n",
    "print(round(df_case['TARGET'].mean()*100, 2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Experimento inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split da base em treino e teste\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(df_case.drop(columns = ['ID', 'TARGET']), df_case['TARGET'], test_size = 0.2, random_state = 5456)\n",
    "\n",
    "mlflow.autolog()\n",
    "with mlflow.start_run(run_name='BaseLine'):\n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    attempt1 = xgb.fit(X_train1, Y_train1)\n",
    "\n",
    "    params = attempt1.get_params()\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "\n",
    "    DT_pred= attempt1.predict(X_test1)\n",
    "\n",
    "    values = evaluate_pto_corte(attempt1, X_train1, X_test1, Y_train1, Y_test1, 0.1)\n",
    "    print(values)\n",
    "\n",
    "    # Log the loss metric\n",
    "    metrics = {\n",
    "    \"pto_corte\": values[8],\n",
    "    \"auc_score_train\": values[0],\n",
    "    \"auc_score_test\": values[1],\n",
    "    \"profit_percent_train\":round((values[2]/values[3])*100, 2),\n",
    "    \"profit_percent_test\": round((values[4]/values[5])*100, 2),\n",
    "    }\n",
    "\n",
    "    mlflow.log_artifact(local_path=\"model_train.ipynb\")\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=attempt1,\n",
    "        artifact_path=\"Model\",\n",
    "        input_example=X_train1.head(2),\n",
    "        registered_model_name=\"Baseline_Model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tratamento e remoção de features com pouca variabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variancia = removeUnvariable(df_case, df_case.columns,0.0) \n",
    "train_vars = df_case.drop(columns = variancia)\n",
    "equals = []\n",
    "for x in train_vars:\n",
    "    for y in train_vars:\n",
    "        if x != y:\n",
    "            if df_case[x].equals(df_case[y]):\n",
    "                if (y,x) not in equals:\n",
    "                    equals.append((x, y))\n",
    "                    \n",
    "\n",
    "drop_cols = [x[1] for x in equals] \n",
    "\n",
    "\n",
    "df_final = train_vars.drop(columns = drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Novo exmperimento sem as features com pouca variabilidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(df_final.drop(columns = ['ID', 'TARGET']), df_final['TARGET'], test_size = 0.2, random_state = 5456)\n",
    "\n",
    "\n",
    "mlflow.autolog()\n",
    "with mlflow.start_run(run_name='Features_Treatment', description=\"removidas variáveis constantes e repetidas do dataframe\"):\n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    attempt2 = xgb.fit(X_train2, Y_train2)\n",
    "\n",
    "\n",
    "\n",
    "    params = attempt2.get_params()\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "\n",
    "    DT_pred= attempt2.predict(X_test2)\n",
    "\n",
    "    values = evaluate_pto_corte(attempt2, X_train2, X_test2, Y_train2, Y_test2, 0.1)\n",
    "    print(values)\n",
    "\n",
    "    # Log the loss metric\n",
    "    metrics = {\n",
    "    \"pto_corte\": values[8],\n",
    "    \"auc_score_train\": values[0],\n",
    "    \"auc_score_test\": values[1],\n",
    "    \"profit_percent_train\":round((values[2]/values[3])*100, 2),\n",
    "    \"profit_percent_test\": round((values[4]/values[5])*100, 2),\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=attempt2,\n",
    "        artifact_path=\"Model\",\n",
    "        input_example=X_train2.head(2),\n",
    "        registered_model_name=\"Case_Data_Master\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Analise e transformação e remoção de mais features e feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula a matriz de correlação de Spearman para remoção de variaveis altamente correlacionadas com drop de variaveis acima de 95% de correção \n",
    "spm_corr =df_final.corr(method='spearman').abs() #Spearman é menos sensivel a outliers\n",
    "\n",
    "upper_tri = spm_corr.where(np.triu(np.ones(spm_corr.shape),k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)] \n",
    "\n",
    "df_corr = df_final.drop(columns = to_drop)\n",
    "\n",
    "#Identificação de variáveis inteiras com exatamente dois valores distintos (flags)\n",
    "\n",
    "vars_int = df_corr.select_dtypes('int64').drop(columns = ['ID']).columns\n",
    "flags_ = [x for x in df_corr[vars_int].columns if len(df_corr[x].unique()) == 2] \n",
    "\n",
    "cat_vars = [x for x in df_corr[vars_int].columns if len(df_corr[x].unique()) > 2] + ['TARGET'] #variáveis inteiras com + de dois valores distintos\n",
    "\n",
    "#feature engineering\n",
    "\n",
    "# feature enginnering agrupando por 'num_var4' e calculando a média de 'TARGET'.\n",
    "new_df = pd.DataFrame(df_corr.groupby('num_var4').mean()['TARGET'].sort_values(ascending = False))\n",
    "new_df = new_df.reset_index().reset_index()\n",
    "df_final_eng = new_df[['index', 'num_var4']].join(df_corr.set_index('num_var4'), on= 'num_var4')#\n",
    "\n",
    "df_final_eng.rename(columns = {'index':'var4_ordered'}, inplace = True)\n",
    "\n",
    "# feature enginnering agrupando por 'num_var5_0' e calculando a média de 'TARGET'.\n",
    "new_df = pd.DataFrame(df_corr.groupby('num_var5_0').mean()['TARGET'].sort_values(ascending = False))\n",
    "new_df = new_df.reset_index().reset_index()\n",
    "df_final_eng = new_df[['index', 'num_var5_0']].join(df_final_eng.set_index('num_var5_0'), on= 'num_var5_0')\n",
    "df_final_eng.rename(columns = {'index':'num_var5_0_ordered'}, inplace = True)\n",
    "\n",
    "# nova coluna 'zero_info' que conta o número de zeros em cada linha do DataFrame.\n",
    "df_final_eng['zero_info'] =(df_final_eng == 0).astype(int).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Novo teste após as transformações descritas em 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_final_eng['TARGET']\n",
    "X = df_final_eng.drop(columns = ['TARGET'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X.drop(columns = ['ID']), y, test_size = 0.2, random_state = 5456)\n",
    "\n",
    "mlflow.autolog()\n",
    "with mlflow.start_run(run_name='Feature Engineering', description=\"Criação de novas vars e removação de vars irrelevantes\"):\n",
    "    xgb = XGBClassifier(seed = 2938)\n",
    "\n",
    "    model_xgb = xgb.fit(X_train, Y_train)\n",
    "\n",
    "    params = model_xgb.get_params()\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "\n",
    "    DT_pred= model_xgb.predict(X_test)\n",
    "\n",
    "    values = evaluate_pto_corte(model_xgb, X_train, X_test, Y_train, Y_test, 0.1)\n",
    "    print(values)\n",
    "\n",
    "    # Log the loss metric\n",
    "    metrics = {\n",
    "    \"pto_corte\": values[8],\n",
    "    \"auc_score_train\": values[0],\n",
    "    \"auc_score_test\": values[1],\n",
    "    \"profit_percent_train\":round((values[2]/values[3])*100, 2),\n",
    "    \"profit_percent_test\": round((values[4]/values[5])*100, 2),\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model_xgb,\n",
    "        artifact_path=\"Model\",\n",
    "        input_example=X_train.head(2),\n",
    "        registered_model_name=\"Case_Data_Master\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Novo treinamento testando o balanceamento das classes usando a técnica undersampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino com Undersampling\n",
    "df_under = X_train\n",
    "df_under[\"TARGET\"] = Y_train\n",
    "\n",
    "qtd_c1 = sum(Y_train)\n",
    "\n",
    "classe_1 = df_under[df_under[\"TARGET\"] == 1]\n",
    "classe_0 = df_under[df_under['TARGET'] == 0].sample(qtd_c1)\n",
    "\n",
    "df_under = pd.concat([classe_0, classe_1]) \n",
    "X_trainUnder = df_under.drop(columns = ['TARGET'])\n",
    "Y_trainUnder = df_under['TARGET']\n",
    "\n",
    "#Treino com Undersampling\n",
    "df_under = X_train\n",
    "df_under[\"TARGET\"] = Y_train\n",
    "\n",
    "qtd_c1 = sum(Y_train)\n",
    "\n",
    "classe_1 = df_under[df_under[\"TARGET\"] == 1]\n",
    "classe_0 = df_under[df_under['TARGET'] == 0].sample(qtd_c1)\n",
    "\n",
    "df_under = pd.concat([classe_0, classe_1]) \n",
    "X_trainUnder = df_under.drop(columns = ['TARGET'])\n",
    "Y_trainUnder = df_under['TARGET']\n",
    "\n",
    "\n",
    "mlflow.autolog()\n",
    "with mlflow.start_run(run_name='Undersampling', description=\"Teste com Undersampling devido a classe ser desbalanceada\"):\n",
    "    \n",
    "    model_xgb_Under = xgb.fit(X_trainUnder, Y_trainUnder)\n",
    "\n",
    "    params = model_xgb_Under.get_params()\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "\n",
    "    DT_pred= model_xgb_Under.predict(X_test)\n",
    "\n",
    "    values = evaluate_pto_corte(model_xgb_Under, X_trainUnder, X_test, Y_trainUnder, Y_test, 0.1)\n",
    "    print(values)\n",
    "\n",
    "    # Log the loss metric\n",
    "    metrics = {\n",
    "    \"pto_corte\": values[8],\n",
    "    \"auc_score_train\": values[0],\n",
    "    \"auc_score_test\": values[1],\n",
    "    \"profit_percent_train\":round((values[2]/values[3])*100, 2),\n",
    "    \"profit_percent_test\": round((values[4]/values[5])*100, 2),\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model_xgb_Under,\n",
    "        artifact_path=\"Model\",\n",
    "        input_example=X_train.head(2),\n",
    "        registered_model_name=\"Case_Data_Master\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Novo experimento otimizando hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definição dos hiperparâmetros a serem otimizados, incluindo lambda, alpha, colsample_bytree, max_depth e min_child_weight.\n",
    "#Criação de um modelo XGBClassifier com os hiperparâmetros sugeridos.\n",
    "# Execução da validação cruzada (cross-validation) com 5 folds, usando a métrica de lucro máximo.\n",
    "# Registro dos parâmetros e da métrica de lucro máximo no MLflow.\n",
    "\n",
    "max_profit = make_scorer(lucro_maximo, greater_is_better=True)\n",
    "\n",
    "def objective(trial):\n",
    "  \n",
    "  mlflow.autolog()\n",
    "  \n",
    "  with mlflow.start_run(run_name= str(trial), nested=True):\n",
    "\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [5, 9, 11]),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = XGBClassifier(**param)  \n",
    "\n",
    "    cval = cross_val_score(model, X_train, Y_train, \n",
    "                             cv=KFold(n_splits=5,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=42),\n",
    "                                 verbose= 3, scoring = max_profit,\n",
    "                            n_jobs= 1\n",
    "                            )\n",
    "    \n",
    "    print(\"cval\", cval)\n",
    "\n",
    "    mlflow.log_params(param)\n",
    "    mlflow.log_metric('max_profit_kfold', cval.mean())\n",
    "    # Save the model as an artifact\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"Model\",\n",
    "        input_example=X_train.head(2),\n",
    "        registered_model_name=\"Case_Data_Master\",\n",
    "    )\n",
    "    \n",
    "    return cval.mean()\n",
    "  \n",
    "  \n",
    "\n",
    "with mlflow.start_run(run_name=\"Optuna\") as mlflow_parent:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=5)\n",
    "    print('Number of finished trials:', len(study.trials))\n",
    "    print('Best trial:', study.best_trial.params)\n",
    "\n",
    "Best_trial = study.best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Treinamento de novo modelo utilizando os melhores parametros definidos pelo Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.autolog()\n",
    "with mlflow.start_run(run_name='Optuna Best Model', description=\"Modelo usando os melhores parametros do optuna\"):\n",
    "    \n",
    "    #Best_trial = {'lambda': 0.01444365452315395, 'learning_rate': 0.09, 'n_estimators': 138, 'max_depth': 5, 'random_state': 2020, 'min_child_weight': 25}\n",
    "\n",
    "    model = XGBClassifier(**Best_trial)\n",
    "    model_optuna = model.fit(X_train, Y_train)\n",
    "\n",
    "    params = model_optuna.get_params()\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    values = evaluate_pto_corte(model_optuna, X_train, X_test, Y_train, Y_test, 0.1)\n",
    "    print(values)\n",
    "\n",
    "    # Log the loss metric\n",
    "    metrics = {\n",
    "    \"pto_corte\": values[8],\n",
    "    \"auc_score_train\": values[0],\n",
    "    \"auc_score_test\": values[1],\n",
    "    \"profit_percent_train\":round((values[2]/values[3])*100, 2),\n",
    "    \"profit_percent_test\": round((values[4]/values[5])*100, 2),\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model_optuna,\n",
    "        artifact_path=\"Model\",\n",
    "        input_example=X_train.head(2),\n",
    "        registered_model_name=\"Case_Data_Master\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Filtro de feature mais importantes para o modelo de acordo com feature importance e novo treino "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração da feature importance do modelo treinado.\n",
    "# Filtro das features cuja importância é maior que 0.02 \n",
    "\n",
    "fi = list(zip(model_optuna.get_booster().feature_names, model_optuna.feature_importances_))\n",
    "try_features = [x[0] for x in fi if x[1] > 0.02]\n",
    "\n",
    "mlflow.autolog()\n",
    "with mlflow.start_run(run_name='Final Model Feature Reduction', description=\"Deixando apenas a top 40 vars\"):\n",
    "    \n",
    "    Best_trial = {'lambda': 0.01444365452315395, 'learning_rate': 0.09, 'n_estimators': 138, 'max_depth': 5, 'random_state': 2020, 'min_child_weight': 25}\n",
    "\n",
    "    model = XGBClassifier(**Best_trial)\n",
    "    model_optuna = model.fit(X_train[try_features], Y_train)\n",
    "    \n",
    "    params = model_optuna.get_params()\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    values = evaluate_pto_corte(model_optuna, X_train[try_features], X_test[try_features], Y_train, Y_test, 0.1)\n",
    "    print(values)\n",
    "\n",
    "    # Log the loss metric\n",
    "    metrics = {\n",
    "    \"pto_corte\": values[8],\n",
    "    \"auc_score_train\": values[0],\n",
    "    \"auc_score_test\": values[1],\n",
    "    \"profit_percent_train\":round((values[2]/values[3])*100, 2),\n",
    "    \"profit_percent_test\": round((values[4]/values[5])*100, 2),\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model_optuna,\n",
    "        artifact_path=\"Model\",\n",
    "        input_example=X_train[try_features].head(2),\n",
    "        registered_model_name=\"Case_Data_Master\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os experimentos realizados assim como as métricas de cada um podem ser observados no dagshub:     \n",
    "https://dagshub.com/joycesafg/DataMaster_Case/experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
